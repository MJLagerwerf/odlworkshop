{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learned Reconstruction\n",
    "\n",
    "This notebook demonstrates how to use ODL to perform learned reconstruction of the famous MNIST dataset.\n",
    "\n",
    "We demonstrate three ways of doing this\n",
    "\n",
    "* Fully learned reconstruction\n",
    "* Learned post-processing\n",
    "* Learned Primal-Dual reconstruction\n",
    "\n",
    "and we also compare to a simple FBP-based reconstruction, the results should be approximately\n",
    "\n",
    "| Method                 |   Error  |\n",
    "|:-----------------------|:--------:|\n",
    "| FBP                    | 0.1510   |\n",
    "| Fully learned          | 0.0240   |\n",
    "| FBP + learned denoiser | 0.0197   |\n",
    "| Learned Primal-Dual    | 0.0151   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n",
    "\n",
    "This should run without errors if all dependencies are installed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import odl\n",
    "import odl.contrib.tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start a tensorflow session\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "# Set the random seed to enable reproducible code\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create operators using ODL\n",
    "\n",
    "Here we create the needed operators in ODL as usual, we then convert them to tensorflow-compatible functions using the `odl.contrib.tensorflow.as_tensorflow_layer` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ODL data structures\n",
    "space = odl.uniform_discr([-14, -14], [14, 14], [28, 28],\n",
    "                          dtype='float32')\n",
    "\n",
    "geometry = odl.tomo.parallel_beam_geometry(space, num_angles=5)\n",
    "operator = odl.tomo.RayTransform(space, geometry)\n",
    "fbp_op = odl.tomo.fbp_op(operator)\n",
    "\n",
    "# Create tensorflow wrappers\n",
    "tf_op = odl.contrib.tensorflow.as_tensorflow_layer(operator)\n",
    "tf_op_adj = odl.contrib.tensorflow.as_tensorflow_layer(operator.adjoint)\n",
    "tf_fbp_op = odl.contrib.tensorflow.as_tensorflow_layer(fbp_op, name=\"FBP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and utilities\n",
    "\n",
    "We now need to get the data we will use, which in this case is the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, a set of digits 70000 hand-written digits, of which 60000 are used for training and 10000 for testing.\n",
    "\n",
    "In addition to this, we create a utility `generate_data` which generates sinograms for each digit, as well as a function `evaluate(...)` that we will use to evaluate how good a reconstruction is and `visualize(...)` which shows an example reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_data(images):\n",
    "    \"\"\"Generate data from images\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images : np.array of shape [Batch, 28, 28, 1]\n",
    "        The images (in reconstruction space) which we should create data for.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    sinograms : np.array of shape [Batch, 5, 41, 1]\n",
    "        Noisy sinograms corresponding to ``images``\n",
    "    \"\"\"\n",
    "    data = [operator(image.squeeze()).asarray() +\n",
    "            np.random.randn(*operator.range.shape) for image in images]\n",
    "    return np.array(data)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the first 1000 mnist test points\n",
    "batch = mnist.test.next_batch(1000)\n",
    "test_images = batch[0].reshape([-1, 28, 28, 1])\n",
    "\n",
    "# Create test data (persistent to save time)\n",
    "test_images = test_images\n",
    "test_data = generate_data(test_images)\n",
    "\n",
    "def evaluate(result_tensor, data_placeholder):\n",
    "    \"\"\"Evaluate a reconstruction method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_tensor : `tf.Tensor`, shape (None, 28, 28, 1)\n",
    "        The tensorflow tensor containing the result of the reonstruction\n",
    "        operator.\n",
    "    data_placeholder : `tf.Tensor`, shape (None, 5, 41, 1)\n",
    "        The tensorflow tensor containing the input to the reconstruction\n",
    "        operator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MSE : float\n",
    "        Mean squared error of the reconstruction.\n",
    "    \"\"\"\n",
    "    result = result_tensor.eval(\n",
    "        feed_dict={data_placeholder: test_data})\n",
    "\n",
    "    return np.mean((result - test_images) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_progress(i, max_iter, result_tensor, data_placeholder, every=100):\n",
    "    \"\"\"\n",
    "    Utility function to display training progress.\n",
    "    \"\"\"\n",
    "    if i % every == 0:\n",
    "        error = evaluate(result_tensor, data_placeholder)\n",
    "        clear_output()\n",
    "        display('{}/{} Error: {:.5f}'.format(i,max_iter, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tensor_name(tensor, default_name=\"Truth\"):\n",
    "    try:\n",
    "        name = tensor.name.split('/')[0]\n",
    "    except AttributeError:\n",
    "        name = default_name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize(result_tensors, data_placeholder, indices=None):\n",
    "    \"\"\"Visualize the result of a reconstruction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    result_tensors : list of `tf.Tensor`, shape (None, 28, 28, 1)\n",
    "        The tensorflow tensor containing the result of the reconstruction\n",
    "        operator.\n",
    "    data_placeholder : `tf.Tensor`, shape (None, 5, 41, 1)\n",
    "        The tensorflow tensor containing the input to the reconstruction\n",
    "        operator.\n",
    "    \"\"\"\n",
    "    if indices is None:\n",
    "        indices = [0]\n",
    "        \n",
    "    results = [result_tensor.eval(\n",
    "        feed_dict={data_placeholder: test_data[indices]}) for result_tensor in result_tensors]\n",
    "    \n",
    "    results_ = [test_images[indices]] + results\n",
    "    names = [get_tensor_name(tensor) for tensor in [None]+result_tensors]\n",
    "    \n",
    "    figsize = 2\n",
    "    fig, rows = plt.subplots(len(indices), len(results_), sharex=True, sharey=True, figsize=(len(results_)*figsize, figsize*len(indices)))\n",
    "    # stupid matplotlib:\n",
    "    if len(indices) == 1:\n",
    "        rows = [rows]\n",
    "    for i, row in enumerate(rows):\n",
    "        for name, res, ax in zip(names, results_, row):\n",
    "            if i == 0:\n",
    "                ax.set_title(name)\n",
    "            ax.imshow(res[i].squeeze(), clim=[0,1], cmap=\"bone\")\n",
    "            ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_indices = np.random.randint(low=0, high=len(test_data), size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create placeholders. Placeholders are needed in tensorflow since tensorflow is a lazy language,\n",
    "and hence we first define the computational graph with placeholders as input, and later we evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('placeholders'):\n",
    "    x_true = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name=\"x_true\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, *operator.range.shape, 1], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the evaluator on the FBP reconstruction as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('FBP Mean squared error: {}'.format(evaluate(tf_fbp_op(y), y)))\n",
    "visualize([tf_fbp_op(y)], y, indices=rand_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Learned Reconstruction\n",
    "\n",
    "The most straight-forward example of a learned reconstruction method is the fully-learned reconstruction. In this method, we use a fully-connected neural network to map data to reconstruction, using no information about the forward operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('flr', reuse=tf.AUTO_REUSE):\n",
    "    with tf.name_scope('fully_learned_reconstruction'):\n",
    "        x = tf.contrib.layers.flatten(y)\n",
    "\n",
    "        x = tf.contrib.layers.fully_connected(x, num_outputs=1024)\n",
    "        x = tf.contrib.layers.fully_connected(x, num_outputs=1024)\n",
    "        x = tf.contrib.layers.fully_connected(x, num_outputs=28 * 28,\n",
    "                                              activation_fn=None)\n",
    "\n",
    "        x_result_fully = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    with tf.name_scope('optimizer_fully'):\n",
    "        loss = tf.reduce_mean((x_result_fully - x_true) ** 2)\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "        \n",
    "# Initialize current variables\n",
    "session.run([v.initializer for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='flr')]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "for i in range(max_iter):\n",
    "    batch = mnist.train.next_batch(5)\n",
    "    images = batch[0].reshape([-1, 28, 28, 1])\n",
    "    data = generate_data(images)\n",
    "\n",
    "    session.run(optimizer, feed_dict={x_true: images, y: data})\n",
    "    \n",
    "    display_progress(i, max_iter, x_result_fully, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize([x_result_fully], y, rand_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FBP + Learned denoiser\n",
    "\n",
    "A more efficient method is to first compute some initial reconstruction (here, a filtered back-projection) and then learn how to improve that reconstruction. By doing this, we only need to learn in image space and can thus use very strong tools from machine learning, including convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('denoise', reuse=tf.AUTO_REUSE):\n",
    "    with tf.name_scope('learned_denoiser'):\n",
    "        x = tf_fbp_op(y)\n",
    "\n",
    "        x = tf.contrib.layers.conv2d(x, num_outputs=32, kernel_size=3)\n",
    "        x = tf.contrib.layers.conv2d(x, num_outputs=32, kernel_size=3)\n",
    "        x = tf.contrib.layers.conv2d(x, num_outputs=1, kernel_size=1,\n",
    "                                     activation_fn=None)\n",
    "\n",
    "        x_result_denoise = x\n",
    "\n",
    "    with tf.name_scope('optimizer_denoiser'):\n",
    "        loss = tf.reduce_mean((x_result_denoise - x_true) ** 2)\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# Initialize all denoising variables\n",
    "session.run([v.initializer for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='denoise')]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(5)\n",
    "    images = batch[0].reshape([-1, 28, 28, 1])\n",
    "    data = generate_data(images)\n",
    "\n",
    "    session.run(optimizer, feed_dict={x_true: images, y: data})\n",
    "\n",
    "    display_progress(i, max_iter, x_result_denoise, y, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize([tf_fbp_op(y), x_result_denoise], y, rand_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learned Primal-Dual\n",
    "\n",
    "In Learned Primal-Dual reconstruction, we embed the forward operator into a neural network and use it as a component in the neural network. By doing so, we can learn in both reconstruction and in data space, and we can use convolutional networks in both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('primal', reuse=tf.AUTO_REUSE):\n",
    "    with tf.name_scope('learned_primal_dual'):\n",
    "        primal = tf_fbp_op(y)\n",
    "        dual = tf.identity(y)\n",
    "\n",
    "        for i in range(1):\n",
    "            dy = tf.concat([dual, tf_op(primal)], axis=-1)\n",
    "            dy = tf.contrib.layers.conv2d(dy, num_outputs=32, kernel_size=3)\n",
    "            dy = tf.contrib.layers.conv2d(dy, num_outputs=1, kernel_size=3,\n",
    "                                          activation_fn=None)\n",
    "            dual = dual + dy\n",
    "\n",
    "            dx = tf.concat([primal, tf_op_adj(dual)], axis=-1)\n",
    "            dx = tf.contrib.layers.conv2d(dx, num_outputs=32, kernel_size=3)\n",
    "            dx = tf.contrib.layers.conv2d(dx, num_outputs=1, kernel_size=3,\n",
    "                                          activation_fn=None)\n",
    "            primal = primal + dx\n",
    "\n",
    "        x_result_lpd = primal\n",
    "\n",
    "    with tf.name_scope('optimizer'):\n",
    "        loss = tf.reduce_mean((x_result_lpd - x_true) ** 2)\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# Initialize all current variables\n",
    "session.run([v.initializer for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='primal')]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "for i in range(max_iter):\n",
    "    batch = mnist.train.next_batch(5)\n",
    "    images = batch[0].reshape([-1, 28, 28, 1])\n",
    "    data = generate_data(images)\n",
    "\n",
    "    session.run(optimizer, feed_dict={x_true: images, y: data})\n",
    "\n",
    "    display_progress(i, max_iter, x_result_lpd, y, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize([x_result_denoise, x_result_lpd], y, rand_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
