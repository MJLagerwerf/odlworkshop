{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classification\n",
    "\n",
    "In this notebook we tackle the perhaps most well known problem in all of machine learning, classifying hand-written digits.\n",
    "\n",
    "The particular dataset we will use is the MNIST (Modified National Institute of Standards and Technology)\n",
    "The digits are 28x28 pixel images that look somewhat like this:\n",
    "\n",
    "![](https://user-images.githubusercontent.com/2202312/32365318-b0ccc44a-c079-11e7-8fb1-6b1566c0bdc4.png)\n",
    "\n",
    "Each digit has been hand classified, e.g. for the above 9-7-0-9-0-...\n",
    "\n",
    "Our task is to teach a machine to perform this classification, i.e. we want to find a function $\\mathcal{T}_\\theta$ such that\n",
    "\n",
    "| | |\n",
    "|-|-|\n",
    "|$\\mathcal{T}_\\theta$(|<img align=\"center\" src=\"https://user-images.githubusercontent.com/2202312/33177374-b134e572-d062-11e7-87c7-0574c6f5bee9.png\" width=\"28\"/>|) = 4|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n",
    "\n",
    "This should run without errors if all dependencies are installed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start a tensorflow session\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "# Set the random seed to enable reproducible code\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and utilities\n",
    "\n",
    "We now need to get the data we will use, which in this case is the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, a set of digits 70000 hand-written digits, of which 60000 are used for training and 10000 for testing.\n",
    "\n",
    "In addition to this, we create a utility `evaluate(...)` that we will use to evaluate how good the classification is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get MNIST data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the 10000 mnist test points\n",
    "batch = mnist.test.next_batch(10000)\n",
    "test_images = batch[0].reshape([-1, 28, 28, 1])\n",
    "test_labels = batch[1]\n",
    "\n",
    "def evaluate(result_tensor, data_placeholder):\n",
    "    \"\"\"Evaluate a reconstruction method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_tensor : `tf.Tensor`, shape (None,)\n",
    "        The tensorflow tensor containing the result of the classification.\n",
    "    data_placeholder : `tf.Tensor`, shape (None, 28, 28, 1)\n",
    "        The tensorflow tensor containing the input to the classification operator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MSE : float\n",
    "        Mean squared error of the reconstruction.\n",
    "    \"\"\"\n",
    "    result = result_tensor.eval(\n",
    "        feed_dict={data_placeholder: test_images})\n",
    "\n",
    "    return np.mean(result == test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create placeholders. Placeholders are needed in tensorflow since tensorflow is a lazy language,\n",
    "# and hence we first define the computational graph with placeholders as input, and later we evaluate it.\n",
    "with tf.name_scope('placeholders'):\n",
    "    images = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "    true_labels = tf.placeholder(tf.int32, shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "We start with [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression), perhaps the most well known and widely applied classification method.\n",
    "\n",
    "The first problem we need to solve is that the values we try to regress against are discrete (e.g. [0, 1, 2, ..., 9]) which does not work very well with continuous optimization. To solve this we convert the values to a one-hot encoding, embedding the values into $\\mathbb{R}^{10}$:\n",
    "\n",
    "```\n",
    ">>> one_hot([0, 1, 2], depth=3)\n",
    "[[ 1.,  0.,  0.],\n",
    " [ 0.,  1.,  0.],\n",
    " [ 0.,  0.,  1.]]\n",
    "```\n",
    "\n",
    "this can also be seen as a probabilistic encoding, i.e. we can estimate that a number is 10% 1 and 90% 2. For our training data, we have 100% certanity for each digit. We use the cross entropy to measure the distance between two such probability distributions.\n",
    "\n",
    "The estimator used for logistic regression is\n",
    "\n",
    "$$\n",
    "p_i = \\frac{\\langle w_i, x \\rangle + b_i}{\\sum_{j=0}^9 (\\langle w_j, x \\rangle + b_j)}\n",
    "$$\n",
    "\n",
    "Where $p_i$ is the probability of a digigt belonging to a cathegory $i$, $w_i \\in \\mathbb{R}^{28 \\times 28}$ and $b_i \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Average correct: 0.0971\n",
      "100 Average correct: 0.8402\n",
      "200 Average correct: 0.8738\n",
      "300 Average correct: 0.8887\n",
      "400 Average correct: 0.8983\n",
      "500 Average correct: 0.9012\n",
      "600 Average correct: 0.9061\n",
      "700 Average correct: 0.9086\n",
      "800 Average correct: 0.911\n",
      "900 Average correct: 0.913\n",
      "1000 Average correct: 0.9123\n",
      "1100 Average correct: 0.9135\n",
      "1200 Average correct: 0.9145\n",
      "1300 Average correct: 0.9161\n",
      "1400 Average correct: 0.9166\n",
      "1500 Average correct: 0.9177\n",
      "1600 Average correct: 0.9185\n",
      "1700 Average correct: 0.9212\n",
      "1800 Average correct: 0.9198\n",
      "1900 Average correct: 0.9212\n",
      "2000 Average correct: 0.9217\n",
      "2100 Average correct: 0.921\n",
      "2200 Average correct: 0.9211\n",
      "2300 Average correct: 0.9221\n",
      "2400 Average correct: 0.921\n",
      "2500 Average correct: 0.9227\n",
      "2600 Average correct: 0.9228\n",
      "2700 Average correct: 0.9221\n",
      "2800 Average correct: 0.9229\n",
      "2900 Average correct: 0.9228\n",
      "3000 Average correct: 0.9235\n",
      "3100 Average correct: 0.9239\n",
      "3200 Average correct: 0.9232\n",
      "3300 Average correct: 0.9247\n",
      "3400 Average correct: 0.9238\n",
      "3500 Average correct: 0.9241\n",
      "3600 Average correct: 0.9247\n",
      "3700 Average correct: 0.925\n",
      "3800 Average correct: 0.9254\n",
      "3900 Average correct: 0.9248\n",
      "4000 Average correct: 0.9254\n",
      "4100 Average correct: 0.9256\n",
      "4200 Average correct: 0.926\n",
      "4300 Average correct: 0.9255\n",
      "4400 Average correct: 0.9248\n",
      "4500 Average correct: 0.9255\n",
      "4600 Average correct: 0.9271\n",
      "4700 Average correct: 0.9274\n",
      "4800 Average correct: 0.9248\n",
      "4900 Average correct: 0.9275\n",
      "5000 Average correct: 0.926\n",
      "5100 Average correct: 0.925\n",
      "5200 Average correct: 0.9272\n",
      "5300 Average correct: 0.9263\n",
      "5400 Average correct: 0.9257\n",
      "5500 Average correct: 0.9262\n",
      "5600 Average correct: 0.9267\n",
      "5700 Average correct: 0.9274\n",
      "5800 Average correct: 0.9266\n",
      "5900 Average correct: 0.9277\n",
      "6000 Average correct: 0.927\n",
      "6100 Average correct: 0.9278\n",
      "6200 Average correct: 0.9259\n",
      "6300 Average correct: 0.9273\n",
      "6400 Average correct: 0.9277\n",
      "6500 Average correct: 0.928\n",
      "6600 Average correct: 0.927\n",
      "6700 Average correct: 0.9288\n",
      "6800 Average correct: 0.9264\n",
      "6900 Average correct: 0.9272\n",
      "7000 Average correct: 0.928\n",
      "7100 Average correct: 0.928\n",
      "7200 Average correct: 0.9271\n",
      "7300 Average correct: 0.9269\n",
      "7400 Average correct: 0.9272\n",
      "7500 Average correct: 0.9273\n",
      "7600 Average correct: 0.9283\n",
      "7700 Average correct: 0.9261\n",
      "7800 Average correct: 0.9271\n",
      "7900 Average correct: 0.9281\n",
      "8000 Average correct: 0.9286\n",
      "8100 Average correct: 0.9285\n",
      "8200 Average correct: 0.9269\n",
      "8300 Average correct: 0.9266\n",
      "8400 Average correct: 0.9269\n",
      "8500 Average correct: 0.9278\n",
      "8600 Average correct: 0.9292\n",
      "8700 Average correct: 0.9277\n",
      "8800 Average correct: 0.9274\n",
      "8900 Average correct: 0.927\n",
      "9000 Average correct: 0.9284\n",
      "9100 Average correct: 0.9284\n",
      "9200 Average correct: 0.9263\n",
      "9300 Average correct: 0.9263\n",
      "9400 Average correct: 0.9272\n",
      "9500 Average correct: 0.9276\n",
      "9600 Average correct: 0.9281\n",
      "9700 Average correct: 0.9282\n",
      "9800 Average correct: 0.9278\n",
      "9900 Average correct: 0.9279\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('logistic_regression'):\n",
    "    x = tf.contrib.layers.flatten(images)\n",
    "    logits = tf.contrib.layers.fully_connected(x, 10,\n",
    "                                               activation_fn=None)\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    one_hot_labels = tf.one_hot(true_labels, depth=10)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_labels,\n",
    "                                                   logits=logits)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# Initialize all TF variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    train_images = batch[0].reshape([-1, 28, 28, 1])\n",
    "    train_labels = batch[1]\n",
    "\n",
    "    session.run(optimizer, feed_dict={images: train_images, \n",
    "                                      true_labels: train_labels})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('{} Average correct: {}'.format(\n",
    "                i, evaluate(pred, images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "The first \"deep\" neural networks were [multilayer perceptrons](https://en.wikipedia.org/wiki/Multilayer_perceptron), in these we have a function of the following form\n",
    "\n",
    "$$\n",
    "\\rho(W_3\\rho(W_2\\rho(W_1 x + b_1) + b_2) + b_3)\n",
    "$$\n",
    "\n",
    "Where $W_i$ are matrices and $b_i$ vectors. Note that the logistic regression can be cast into this form (how?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Average correct: 0.1431\n",
      "100 Average correct: 0.9093\n",
      "200 Average correct: 0.9247\n",
      "300 Average correct: 0.9429\n",
      "400 Average correct: 0.9459\n",
      "500 Average correct: 0.9513\n",
      "600 Average correct: 0.9529\n",
      "700 Average correct: 0.9576\n",
      "800 Average correct: 0.9587\n",
      "900 Average correct: 0.9626\n",
      "1000 Average correct: 0.9629\n",
      "1100 Average correct: 0.9595\n",
      "1200 Average correct: 0.9656\n",
      "1300 Average correct: 0.9645\n",
      "1400 Average correct: 0.9669\n",
      "1500 Average correct: 0.9682\n",
      "1600 Average correct: 0.9697\n",
      "1700 Average correct: 0.9695\n",
      "1800 Average correct: 0.9689\n",
      "1900 Average correct: 0.9738\n",
      "2000 Average correct: 0.9713\n",
      "2100 Average correct: 0.9719\n",
      "2200 Average correct: 0.9728\n",
      "2300 Average correct: 0.9736\n",
      "2400 Average correct: 0.9745\n",
      "2500 Average correct: 0.9751\n",
      "2600 Average correct: 0.9745\n",
      "2700 Average correct: 0.9737\n",
      "2800 Average correct: 0.9739\n",
      "2900 Average correct: 0.9708\n",
      "3000 Average correct: 0.9761\n",
      "3100 Average correct: 0.9762\n",
      "3200 Average correct: 0.975\n",
      "3300 Average correct: 0.9766\n",
      "3400 Average correct: 0.9772\n",
      "3500 Average correct: 0.9744\n",
      "3600 Average correct: 0.9739\n",
      "3700 Average correct: 0.975\n",
      "3800 Average correct: 0.9759\n",
      "3900 Average correct: 0.9751\n",
      "4000 Average correct: 0.9752\n",
      "4100 Average correct: 0.9764\n",
      "4200 Average correct: 0.9765\n",
      "4300 Average correct: 0.9761\n",
      "4400 Average correct: 0.9749\n",
      "4500 Average correct: 0.9776\n",
      "4600 Average correct: 0.9754\n",
      "4700 Average correct: 0.9756\n",
      "4800 Average correct: 0.9759\n",
      "4900 Average correct: 0.9747\n",
      "5000 Average correct: 0.9762\n",
      "5100 Average correct: 0.9769\n",
      "5200 Average correct: 0.9777\n",
      "5300 Average correct: 0.9773\n",
      "5400 Average correct: 0.9779\n",
      "5500 Average correct: 0.9783\n",
      "5600 Average correct: 0.9755\n",
      "5700 Average correct: 0.9759\n",
      "5800 Average correct: 0.9737\n",
      "5900 Average correct: 0.9744\n",
      "6000 Average correct: 0.9729\n",
      "6100 Average correct: 0.9757\n",
      "6200 Average correct: 0.9769\n",
      "6300 Average correct: 0.9772\n",
      "6400 Average correct: 0.9759\n",
      "6500 Average correct: 0.9776\n",
      "6600 Average correct: 0.9768\n",
      "6700 Average correct: 0.9751\n",
      "6800 Average correct: 0.9776\n",
      "6900 Average correct: 0.9752\n",
      "7000 Average correct: 0.9746\n",
      "7100 Average correct: 0.9747\n",
      "7200 Average correct: 0.9745\n",
      "7300 Average correct: 0.9747\n",
      "7400 Average correct: 0.9738\n",
      "7500 Average correct: 0.9764\n",
      "7600 Average correct: 0.9778\n",
      "7700 Average correct: 0.9769\n",
      "7800 Average correct: 0.9789\n",
      "7900 Average correct: 0.9795\n",
      "8000 Average correct: 0.9767\n",
      "8100 Average correct: 0.9747\n",
      "8200 Average correct: 0.9741\n",
      "8300 Average correct: 0.974\n",
      "8400 Average correct: 0.9771\n",
      "8500 Average correct: 0.9757\n",
      "8600 Average correct: 0.9769\n",
      "8700 Average correct: 0.9774\n",
      "8800 Average correct: 0.9767\n",
      "8900 Average correct: 0.9771\n",
      "9000 Average correct: 0.9765\n",
      "9100 Average correct: 0.978\n",
      "9200 Average correct: 0.977\n",
      "9300 Average correct: 0.9761\n",
      "9400 Average correct: 0.9778\n",
      "9500 Average correct: 0.9777\n",
      "9600 Average correct: 0.9768\n",
      "9700 Average correct: 0.977\n",
      "9800 Average correct: 0.9755\n",
      "9900 Average correct: 0.9792\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('logistic_regression'):\n",
    "    x = tf.contrib.layers.flatten(images)\n",
    "    x = tf.contrib.layers.fully_connected(x, 128)  # the default activation function is ReLU\n",
    "    x = tf.contrib.layers.fully_connected(x, 32)\n",
    "    logits = tf.contrib.layers.fully_connected(x, 10,\n",
    "                                               activation_fn=None)\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    one_hot_labels = tf.one_hot(true_labels, depth=10)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_labels,\n",
    "                                                   logits=logits)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# Initialize all TF variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    train_images = batch[0].reshape([-1, 28, 28, 1])\n",
    "    train_labels = batch[1]\n",
    "\n",
    "    session.run(optimizer, feed_dict={images: train_images, \n",
    "                                      true_labels: train_labels})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('{} Average correct: {}'.format(\n",
    "                i, evaluate(pred, images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional network\n",
    "\n",
    "Convolutional neural networks are a corner-stone of the deep learning revolution. Here instead of using traditionall fully-connected layers which connect each point with all other points, we use spatial convolutions instead. By doing this, we get a translation invariant operator that acts locally. In order to get non-local behaviour we stack several of these on top of each other.\n",
    "\n",
    "The following code is a very simplified convolutional neural network for digit classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Average correct: 0.1646\n",
      "100 Average correct: 0.914\n",
      "200 Average correct: 0.945\n",
      "300 Average correct: 0.9602\n",
      "400 Average correct: 0.9652\n",
      "500 Average correct: 0.9708\n",
      "600 Average correct: 0.9772\n",
      "700 Average correct: 0.9763\n",
      "800 Average correct: 0.9801\n",
      "900 Average correct: 0.9819\n",
      "1000 Average correct: 0.9837\n",
      "1100 Average correct: 0.983\n",
      "1200 Average correct: 0.983\n",
      "1300 Average correct: 0.9846\n",
      "1400 Average correct: 0.9857\n",
      "1500 Average correct: 0.9859\n",
      "1600 Average correct: 0.9841\n",
      "1700 Average correct: 0.9848\n",
      "1800 Average correct: 0.9839\n",
      "1900 Average correct: 0.9838\n",
      "2000 Average correct: 0.9855\n",
      "2100 Average correct: 0.984\n",
      "2200 Average correct: 0.9859\n",
      "2300 Average correct: 0.9852\n",
      "2400 Average correct: 0.9847\n",
      "2500 Average correct: 0.9848\n",
      "2600 Average correct: 0.9862\n",
      "2700 Average correct: 0.9841\n",
      "2800 Average correct: 0.987\n",
      "2900 Average correct: 0.9858\n",
      "3000 Average correct: 0.9861\n",
      "3100 Average correct: 0.9878\n",
      "3200 Average correct: 0.986\n",
      "3300 Average correct: 0.9877\n",
      "3400 Average correct: 0.9862\n",
      "3500 Average correct: 0.9871\n",
      "3600 Average correct: 0.9856\n",
      "3700 Average correct: 0.9876\n",
      "3800 Average correct: 0.9876\n",
      "3900 Average correct: 0.9857\n",
      "4000 Average correct: 0.9849\n",
      "4100 Average correct: 0.9865\n",
      "4200 Average correct: 0.9869\n",
      "4300 Average correct: 0.9859\n",
      "4400 Average correct: 0.988\n",
      "4500 Average correct: 0.9863\n",
      "4600 Average correct: 0.9853\n",
      "4700 Average correct: 0.9874\n",
      "4800 Average correct: 0.986\n",
      "4900 Average correct: 0.9853\n",
      "5000 Average correct: 0.9873\n",
      "5100 Average correct: 0.9873\n",
      "5200 Average correct: 0.9872\n",
      "5300 Average correct: 0.9862\n",
      "5400 Average correct: 0.9867\n",
      "5500 Average correct: 0.9872\n",
      "5600 Average correct: 0.9877\n",
      "5700 Average correct: 0.9875\n",
      "5800 Average correct: 0.9868\n",
      "5900 Average correct: 0.9874\n",
      "6000 Average correct: 0.9875\n",
      "6100 Average correct: 0.9853\n",
      "6200 Average correct: 0.9849\n",
      "6300 Average correct: 0.9846\n",
      "6400 Average correct: 0.987\n",
      "6500 Average correct: 0.9865\n",
      "6600 Average correct: 0.9879\n",
      "6700 Average correct: 0.9882\n",
      "6800 Average correct: 0.9865\n",
      "6900 Average correct: 0.9865\n",
      "7000 Average correct: 0.9852\n",
      "7100 Average correct: 0.9864\n",
      "7200 Average correct: 0.9869\n",
      "7300 Average correct: 0.9865\n",
      "7400 Average correct: 0.9862\n",
      "7500 Average correct: 0.9852\n",
      "7600 Average correct: 0.985\n",
      "7700 Average correct: 0.9869\n",
      "7800 Average correct: 0.9851\n",
      "7900 Average correct: 0.9876\n",
      "8000 Average correct: 0.986\n",
      "8100 Average correct: 0.9872\n",
      "8200 Average correct: 0.9859\n",
      "8300 Average correct: 0.9847\n",
      "8400 Average correct: 0.9857\n",
      "8500 Average correct: 0.9867\n",
      "8600 Average correct: 0.9874\n",
      "8700 Average correct: 0.9867\n",
      "8800 Average correct: 0.9874\n",
      "8900 Average correct: 0.9868\n",
      "9000 Average correct: 0.9855\n",
      "9100 Average correct: 0.9857\n",
      "9200 Average correct: 0.9844\n",
      "9300 Average correct: 0.9873\n",
      "9400 Average correct: 0.9873\n",
      "9500 Average correct: 0.9877\n",
      "9600 Average correct: 0.9872\n",
      "9700 Average correct: 0.9878\n",
      "9800 Average correct: 0.9884\n",
      "9900 Average correct: 0.9872\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('convolutional_network'):\n",
    "    x = tf.contrib.layers.conv2d(images, num_outputs=32, kernel_size=3, stride=2)\n",
    "    x = tf.contrib.layers.conv2d(x, num_outputs=32, kernel_size=3, stride=2)\n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    \n",
    "    x = tf.contrib.layers.fully_connected(x, 128)\n",
    "    logits = tf.contrib.layers.fully_connected(x, 10,\n",
    "                                               activation_fn=None)\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    one_hot_labels = tf.one_hot(true_labels, depth=10)\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_labels,\n",
    "                                                   logits=logits)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# Initialize all TF variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(128)\n",
    "    train_images = batch[0].reshape([-1, 28, 28, 1])\n",
    "    train_labels = batch[1]\n",
    "\n",
    "    session.run(optimizer, feed_dict={images: train_images, \n",
    "                                      true_labels: train_labels})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('{} Average correct: {}'.format(\n",
    "                i, evaluate(pred, images)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
