{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-ray CT reconstruction from real data\n",
    "\n",
    "We perform a 3D CT reconstruction from real cone-beam X-ray data from a rat skull.\n",
    "\n",
    "The data was acquired at the CWI FleX-ray lab by Sophia Coban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import odl\n",
    "import odl_multigrid\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "The dataset consists of 1200 projections in TIFF format, plus an offset and a gain image. We set the paths and check if data files exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/hkohr/SciData/rat_skull/'\n",
    "offset_image_name = 'di0000.tif'\n",
    "gain_image_name = 'io0000.tif'\n",
    "num_projs = 1200\n",
    "proj_image_names = ['scan_{:06}.tif'.format(i) for i in range(num_projs)]\n",
    "\n",
    "# Check existence of all files upfront. No output means everyting OK.\n",
    "for fname in chain([offset_image_name], [gain_image_name], proj_image_names):\n",
    "    full_path = os.path.join(data_path, fname)\n",
    "    if not os.path.exists(full_path):\n",
    "        print('file {} does not exist'.format(full_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the whole data into a Numpy array. To limit the problem size, we take a subset of the projections and subsample each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use every fourth projection\n",
    "angle_slice = np.s_[::4]  # Indexing object to get subsets of the projection images\n",
    "proj_image_names_subset = proj_image_names[angle_slice]\n",
    "num_projs_subset = len(proj_image_names_subset)\n",
    "\n",
    "\n",
    "# Lame way of getting some neighbor of a pixel\n",
    "def neighbor(i, j):\n",
    "    if i > 0:\n",
    "        return i - 1, j\n",
    "    elif j > 0:\n",
    "        return i, j - 1\n",
    "    else:\n",
    "        return i + 1, j\n",
    "\n",
    "    \n",
    "# Function to sum `binning x binning` pixels into one\n",
    "def bin_image(image, binning):\n",
    "    tmp = image.reshape((image.shape[0] // binning, binning, image.shape[1] // binning, binning))\n",
    "    return np.sum(tmp, axis=(1, 3))\n",
    "\n",
    "\n",
    "# Subsample each projection image\n",
    "binning = 2\n",
    "\n",
    "# Get an image to determine the size\n",
    "tmp = np.asarray(Image.open(os.path.join(data_path, offset_image_name)))\n",
    "det_shape_subset = tmp[::binning, ::binning].T.shape\n",
    "\n",
    "# Initialize array holding the full dataset\n",
    "proj_data = np.empty((num_projs_subset,) + det_shape_subset, dtype='float32')\n",
    "print('Data volume shape:', proj_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the data from disk, apply binning, fix dead pixels, normalize the data by the transform\n",
    "\n",
    "$$\n",
    "    y_{\\text{n}} = \\frac{y_{\\text{raw}} - y_{\\text{offset}}}{y_{\\text{gain}} - y_{\\text{offset}}}\n",
    "$$\n",
    "\n",
    "with an offset (\"dark field\") image and a gain (\"bright field\") image. After that, we apply the log transform\n",
    "\n",
    "$$\n",
    "    y = -\\log(y_{\\text{n}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in odl.util.ProgressRange('Reading data, fixing dead pixels', num_projs_subset):\n",
    "    # Read image and rotate from (i,j) to (x,y) convention\n",
    "    fname = proj_image_names_subset[i]\n",
    "    proj = np.asarray(Image.open(os.path.join(data_path, fname)))\n",
    "    proj = np.rot90(proj, -1)\n",
    "    \n",
    "    # Apply binning\n",
    "    proj_data[i] = bin_image(proj, binning)\n",
    "\n",
    "    # Fix dead pixels (very simple method) We only expect a few, so this won't take too long\n",
    "    dead_pixels = np.where(proj_data[i] == 0)\n",
    "    if np.size(dead_pixels) == 0:\n",
    "        continue\n",
    "\n",
    "    neighbors = [np.empty_like(dead_px_i) for dead_px_i in dead_pixels]\n",
    "    for num, (i, j) in enumerate(zip(*dead_pixels)):\n",
    "        inb, jnb = neighbor(i, j)\n",
    "        neighbors[0][num] = inb\n",
    "        neighbors[1][num] = jnb\n",
    "\n",
    "    proj_data[i][dead_pixels] = proj_data[i][neighbors]\n",
    "    \n",
    "\n",
    "offset_image = np.asarray(Image.open(os.path.join(data_path, offset_image_name)))\n",
    "offset_image = bin_image(np.rot90(offset_image, -1), binning)\n",
    "\n",
    "gain_image = np.asarray(Image.open(os.path.join(data_path, gain_image_name)))\n",
    "gain_image = bin_image(np.rot90(gain_image, -1), binning)\n",
    "\n",
    "# Normalize data with gain & offset images, and take the negative log\n",
    "for i in odl.util.ProgressRange('Applying log transform          ', num_projs_subset):\n",
    "    proj_data[i] -= offset_image\n",
    "    proj_data[i] /= gain_image - offset_image\n",
    "    np.log(proj_data[i], out=proj_data[i])\n",
    "    proj_data[i] *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the dark (offset) image, flat field (gain) image, and a sample from the projection images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.rot90(offset_image))\n",
    "plt.title('dark image')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.rot90(gain_image))\n",
    "plt.title('gain image')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Display a sample\n",
    "plt.figure()\n",
    "plt.subplot(221)\n",
    "plt.imshow(np.rot90(proj_data[0]))\n",
    "plt.title('image 0')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(np.rot90(proj_data[75]))\n",
    "plt.title('image 75')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(np.rot90(proj_data[150]))\n",
    "plt.title('image 150')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(np.rot90(proj_data[225]))\n",
    "plt.title('image 225')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Projection images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a simple FBP reconstruction\n",
    "\n",
    "For the reconstruction we set some parameters as read from the various metadata files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object\n",
    "sample_size = 15  # (only x-y radius) [mm]\n",
    "\n",
    "# Geometry\n",
    "sdd = 281.000000  # [mm]\n",
    "sod = 154.999512  # [mm]\n",
    "first_angle = 0.0  # [deg]\n",
    "last_angle = 360.0  # [deg]\n",
    "\n",
    "# Detector\n",
    "det_px_size = 0.149600  # (binned) [mm]\n",
    "det_shape = (972, 768)\n",
    "\n",
    "# Reconstruction (not necessarily needed)\n",
    "voxel_size = 0.082519  # = px_size / magnification  [mm]\n",
    "horiz_center = 481.283422  # [px]\n",
    "vert_center = 387.700535  # [px]\n",
    "\n",
    "# Region of interest (on detector, rest has no object info)\n",
    "xmin = 292.000000  # [px]\n",
    "xmax = 660.000000  # [px]\n",
    "ymin = 292.000000  # [px]\n",
    "ymax = 660.000000  # [px]\n",
    "zmin = 98.000000  # [px]\n",
    "zmax = 686.000000  # [px]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these values we define the ODL geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_partition = odl.uniform_partition(\n",
    "    np.radians(first_angle), np.radians(last_angle), num_projs_subset)\n",
    "\n",
    "det_min_pt = -det_px_size * np.array(det_shape) / 2.0\n",
    "det_max_pt = det_px_size * np.array(det_shape) / 2.0\n",
    "det_partition = odl.uniform_partition(det_min_pt, det_max_pt, det_shape_subset)\n",
    "\n",
    "src_radius = sod\n",
    "det_radius = sdd - sod\n",
    "magnification = (src_radius + det_radius) / src_radius\n",
    "\n",
    "# Account for shift between object center and rotation center\n",
    "rot_center_x = (horiz_center - (xmax + xmin) / 2) * det_px_size / magnification\n",
    "rot_center_z = (vert_center - (zmax + zmin) / 2) * det_px_size / magnification\n",
    "\n",
    "# This currently works by a hack in ODL\n",
    "geometry = odl.tomo.ConeFlatGeometry(\n",
    "    angle_partition, det_partition, src_radius, det_radius,\n",
    "    rot_center=-np.array([rot_center_x, 0, rot_center_z]))\n",
    "\n",
    "print(geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a reconstruction space that matches the resolution of the detector (including the magnification effect):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume size in mm\n",
    "vol_size = np.array([xmax - xmin, ymax - ymin, zmax - zmin])\n",
    "vol_size *= det_px_size / magnification\n",
    "vol_size *= 1.1  # safety margin\n",
    "\n",
    "vol_shift = np.array([rot_center_x, 0, rot_center_z])\n",
    "vol_min_pt = -vol_size / 2 + vol_shift\n",
    "vol_max_pt = vol_size / 2 + vol_shift\n",
    "vol_shape = (vol_size / min(det_partition.cell_sides) * magnification).astype(int)\n",
    "vol_shape = (np.ceil(vol_shape / 32) * 32).astype(int)  # next multiple of 32\n",
    "\n",
    "reco_space = odl.uniform_discr(vol_min_pt, vol_min_pt + vol_size, vol_shape,\n",
    "                               dtype='float32')\n",
    "print('Reconstruction space:\\n', reco_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a simple FBP reconstruction and plot 3 \"interesting\" orthoslices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ray_trafo = odl.tomo.RayTransform(reco_space, geometry)\n",
    "full_fbp_op = odl.tomo.fbp_op(full_ray_trafo, padding=False,\n",
    "                              filter_type='Hamming', frequency_scaling=0.99)\n",
    "full_fbp_reco = full_fbp_op(proj_data)\n",
    "\n",
    "# Display window (min/max coordinate)\n",
    "x_window = (-9, 6)\n",
    "y_window = (-5, 10)\n",
    "z_window = (-25, 5)\n",
    "\n",
    "_ = full_fbp_reco.show(coords=[x_window, y_window, np.mean(z_window)], clim=[0, 0.6])\n",
    "_ = full_fbp_reco.show(coords=[x_window, np.mean(y_window), z_window], clim=[0, 0.6])\n",
    "_ = full_fbp_reco.show(coords=[np.mean(x_window), y_window, z_window], clim=[0, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the feasibility of iterative reconstruction, let us look at the evaluation times of the forward operator and the adjoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit full_ray_trafo(full_ray_trafo.domain.zero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit full_ray_trafo.adjoint(full_ray_trafo.range.zero())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-resolution reconstruction\n",
    "\n",
    "To enable iterative reconstruction for this problem, we reduce the problem size by using two different resolutions: full resolution in the region of interest (ROI) and significantly lower resolution in the rest.\n",
    "\n",
    "Mathematically, we write a function $x$ as the sum of two functions $x = x_1 + x_2$, where $x_2$ represents the region of interest and $x_1$ the rest (coarsely discretized later on).\n",
    "\n",
    "Hence, with our forward operator $R$, the cone-beam ray transform, we get two contributions to the data,\n",
    "\n",
    "$$\n",
    "    y = R\\big(M(x_1)\\big) + R(x_2).\n",
    "$$\n",
    "\n",
    "Here, $M$ masks the ROI to not count it twice in the forward projection.\n",
    "\n",
    "We can now see $x_1$ and $x_2$ as two independent variables and perform variational reconstruction with different regularization in the different parts of the volume. In the example below, we solve\n",
    "\n",
    "$$\n",
    "    x^* = (x_1^*, x_2^*) = \\text{argmin}_{x_1, x_2} \\left[ \\|A(x_1, x_2) - y\\|_2^2 + \\alpha_1 \\|\\nabla x_1\\|_2^2 + \\text{TV}(x_2) \\right],\n",
    "$$\n",
    "\n",
    "i.e., we use TV regularization in the ROI and a smoothness prior (unimportant) outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a smaller space that only contains the ROI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take full resolution in the ROI\n",
    "roi_min_pt = np.array([-9.0, -5.0, -25.0])\n",
    "roi_max_pt = np.array([6.0, 10.0, 5.0])\n",
    "roi_shape = np.ceil((roi_max_pt - roi_min_pt) / reco_space.cell_sides).astype(int)\n",
    "print('ROI shape:', roi_shape)\n",
    "X2 = odl.uniform_discr(roi_min_pt, roi_max_pt, roi_shape,\n",
    "                       dtype=reco_space.dtype)\n",
    "\n",
    "# Take 16 times coarser discretization outside\n",
    "outer_shape = np.ceil(np.divide(reco_space.shape, 16)).astype(int)\n",
    "print('Outer shape:', outer_shape)\n",
    "X1 = odl.uniform_discr(reco_space.min_pt, reco_space.max_pt, outer_shape,\n",
    "                       dtype=reco_space.dtype)\n",
    "y = proj_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the operators and functionals for the problem formulation. For the data match, we have the forward operator\n",
    "\n",
    "$$\n",
    "    A: X_1 \\times X_2 \\to Y, \\quad A(x_1, x_2) = R_1\\big(M(x_1)\\big) + R_2(x_2)\n",
    "$$\n",
    "\n",
    "and the squared $L^2$ data fit, resulting in the total data matching functional\n",
    "\n",
    "$$\n",
    "    \\|A(x_1, x_2) - y\\|_2^2.\n",
    "$$\n",
    "\n",
    "Next, we generate a gradient operator\n",
    "\n",
    "$$\n",
    "    G_1 = \\nabla: X_1 \\to X_1^3\n",
    "$$\n",
    "\n",
    "on $X_1$ and the squared $L^2$ norm on its range, to get the smooth regularizer $\\|\\nabla x_1\\|_2^2$.\n",
    "\n",
    "For the TV term, we use the gradient on $X_2$,\n",
    "\n",
    "$$\n",
    "    G_2 = \\nabla: X_2: \\to X_2^3,\n",
    "$$\n",
    "\n",
    "to define the TV functional $TV(x_2) = \\|x_2\\|_1$.\n",
    "\n",
    "We put together all the pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionals\n",
    "# D = data matching functional: Y -> R, ||. - g||_Y^2\n",
    "# S1 = (alpha1 * squared L2-norm): X1^3 -> R, for Tikhonov functional\n",
    "# S2 = (alpha2 * L12-Norm): X2^3 -> R, for isotropic TV\n",
    "\n",
    "# Operators\n",
    "# A = broadcasting forward operator: X1 x X2 -> Y\n",
    "# G1 = spatial gradient: X1 -> X1^2\n",
    "# G2 = spatial gradient: X2 -> X2^2\n",
    "# B1 = G1 extended to X1 x X2, B1(f1, f2) = G1(f1)\n",
    "# B2 = G2 extended to X1 x X2, B2(f1, f2) = G2(f2)\n",
    "\n",
    "R1 = odl.tomo.RayTransform(X1, geometry)\n",
    "R2 = odl.tomo.RayTransform(X2, geometry)\n",
    "M = odl_multigrid.MaskingOperator(X1, roi_min_pt, roi_max_pt)\n",
    "\n",
    "A1 = R1 * M\n",
    "A2 = R2\n",
    "A = odl.ReductionOperator(A1, A2)\n",
    "\n",
    "G1 = odl.Gradient(X1, pad_mode='symmetric')\n",
    "G2 = odl.Gradient(X2, pad_mode='order1')\n",
    "\n",
    "alpha1 = 1e0\n",
    "alpha2 = 5e-2\n",
    "S1 = alpha1 * odl.solvers.L2NormSquared(G1.range)\n",
    "S2 = alpha2 * odl.solvers.GroupL1Norm(G2.range)\n",
    "\n",
    "B1 = G1 * odl.ComponentProjection(X1 * X2, 0)\n",
    "B2 = G2 * odl.ComponentProjection(X1 * X2, 1)\n",
    "\n",
    "D = odl.solvers.L2NormSquared(A.range).translated(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check how much we gained regarding runtimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A(A.domain.zero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit A.adjoint(A.range.zero())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward operator is not so much faster, since we still have the same number of rays to compute, i.e., forward projection scales with the number of angles and detector pixels. That is something to improve later.\n",
    "\n",
    "However, the adjoint is much faster since it scales with the number voxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the usual steps and reconstruct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the solver\n",
    "f = odl.solvers.ZeroFunctional(A.domain)  # unused\n",
    "g = [D, S1, S2]\n",
    "L = [A, B1, B2]\n",
    "\n",
    "# Operator norm estimation for the step size parameters\n",
    "xstart = odl.phantom.white_noise(A.domain)\n",
    "A_norm = odl.power_method_opnorm(A, maxiter=10)\n",
    "B1_norm = odl.power_method_opnorm(B1, xstart=xstart, maxiter=10)\n",
    "B2_norm = odl.power_method_opnorm(B2, xstart=xstart, maxiter=10)\n",
    "\n",
    "print('||A||', A_norm)\n",
    "print('||B1||', B1_norm)\n",
    "print('||B2||', B2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need tau * sum[i](sigma_i * opnorm_i^2) < 4 for convergence, so we\n",
    "# choose tau and set sigma_i = c / (tau * opnorm_i^2) such that sum[i](c) < 4\n",
    "tau = 1.0\n",
    "opnorms = [A_norm, B1_norm, B2_norm]\n",
    "sigmas = [3.0 / (tau * len(opnorms) * opnorm ** 2) for opnorm in opnorms]\n",
    "\n",
    "callback = odl.solvers.CallbackPrintIteration(step=20)\n",
    "\n",
    "x = A.domain.zero()\n",
    "odl.solvers.douglas_rachford_pd(\n",
    "    x, f, g, L, tau, sigmas, niter=200, callback=callback)\n",
    "\n",
    "x1, x2 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = x2.show(coords=[None, None, np.mean(z_window)], clim=[0, 0.6])\n",
    "_ = x2.show(coords=[None, np.mean(y_window), None], clim=[0, 0.6])\n",
    "_ = x2.show(coords=[np.mean(x_window), None, None], clim=[0, 0.6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
